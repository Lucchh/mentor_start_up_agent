# Luc's AI Agent - CrewAI Digital Twin

A comprehensive CrewAI-powered system that simulates Luc's learning process through collaborative AI agents. Features both a NANDA-based HTTP API server and a modular MCP (Model Context Protocol) package for flexible deployment.

## 🚀 Features

- **Dual-Agent System**: Research agent + Content mentor agent
- **Multiple Deployment Options**: NANDA HTTP API + MCP server package
- **Topic-Driven Processing**: Send a topic string; get back a clear summary
- **Sequential Processing**: Agents work together in a structured workflow
- **Beginner-Friendly Output**: Complex topics explained in simple terms
- **Environment Configuration**: Uses `.env` for keys and domain config
- **Modular Architecture**: Clean package structure with proper dependencies

## 📁 Project Structure

```
AI Agent/
├── Assignment_1/
│   ├── main.py                 # NANDA-based HTTP API server
│   ├── mentor_mcp/            # MCP server package
│   │   ├── __init__.py        # Package initialization
│   │   ├── main.py            # MCP server implementation
│   │   └── __main__.py        # Module entry point
│   ├── pyproject.toml         # Package configuration
│   ├── requirements.txt       # Python dependencies
│   ├── .gitignore            # Git ignore patterns
│   ├── simclr_explained.md   # Example output file
│   ├── ai_agent_explained.md # Example output file
│   ├── test_local.py         # Local testing script
│   ├── run_adapter.py        # NANDA adapter runner
│   └── README.md          
```

## 🛠️ Setup

### Prerequisites

- Python 3.8 or higher
- Anthropic API key (used by the NANDA wrapper)

### Installation

1. **Navigate to the project directory:**
   ```bash
   cd "/Users/lucchen/Desktop/AI Agent"
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies and package:**
   ```bash
   cd Assignment_1
   pip install -r requirements.txt
   pip install -e .  # Install mentor_mcp package in development mode
   ```

4. **Set up environment variables:**

   Create a `.env` file in the `Assignment_1` directory with at least your Anthropic key. Optionally set a domain if you have one:
   ```bash
   cd Assignment_1
   echo "ANTHROPIC_API_KEY=your-anthropic-key-here" > .env
   echo "DOMAIN_NAME=your-domain.example" >> .env  # optional
   ```

   Or set them as environment variables in your shell:
   ```bash
   export ANTHROPIC_API_KEY="your-anthropic-key-here"
   export DOMAIN_NAME="your-domain.example"   # optional
   ```

## 🎯 Usage

### Option 1: NANDA HTTP API Server

1. **Start the NANDA server:**
   ```bash
   python main.py
   ```

2. **Send a message (topic) to the server:**
   - Provide any technical topic string (e.g., "Machine Learning", "Neural Networks", "SimCLR").
   - If an empty message is provided, the default topic is "SimCLR".
   - The server returns the final explanation text generated by the crew.

3. **Server details:**
   - The NANDA adapter starts an HTTP API and handles routing
   - Check the terminal logs for the exposed URL and usage details

### Option 2: MCP Server Package

1. **Run as a module:**
   ```bash
   python -m mentor_mcp
   ```

2. **Run using the CLI command:**
   ```bash
   mentor_mcp
   ```

3. **Use in your code:**
   ```python
   from mentor_mcp import crew_agent_logic
   
   result = crew_agent_logic("Machine Learning")
   print(result)
   ```

### Example Flow

```bash
# NANDA Server
$ python main.py
# NANDA starts and prints server information / public URL (if configured)
# Use that endpoint to POST a message containing your topic string

# MCP Server
$ python -m mentor_mcp
# MCP server starts and listens for stdio transport
```

### Output

The server returns a text response with:
- Clear definitions
- Key concepts explained simply
- How things work (step-by-step)
- Real-world examples
- Why it's important

## 🔧 Configuration

### Customizing Agents

You can modify the agents in either `main.py` (NANDA version) or `mentor_mcp/main.py` (MCP version):

- **Research Agent**: Change the role, goal, or backstory
- **Mentor Agent**: Adjust the simplification approach
- **LLM Settings**: Specify different models or temperature settings

Example customization:
```python
def create_student_agent():
    return Agent(
        role="Harvard Data Science Student",
        goal="Summarize technical concepts clearly and accurately",
        backstory="""You are Luc, a Harvard Data Science student...""",
        verbose=True,
        allow_delegation=False,
        model="gpt-4o-mini",  # Specify model
        temperature=0.2       # Control randomness
    )
```

### Package Development

To modify the MCP package:

1. **Edit the package code** in `mentor_mcp/`
2. **Reinstall in development mode**: `pip install -e .`
3. **Test changes** using any of the run methods above

 

## 🐛 Troubleshooting

### Common Issues

1. **"No module named 'crewai'"**
   - Make sure you're in the virtual environment
   - Run `pip install -r requirements.txt`

2. **API Key Error**
   - Verify `ANTHROPIC_API_KEY` is set correctly in your `.env` or shell
   - Check that you have sufficient API credits
   - Ensure the `.env` file is in the `Assignment_1` directory

3. **Server Not Reachable**
   - Confirm the server is running in the terminal
   - If using a custom `DOMAIN_NAME`, verify DNS/routing is correctly configured
   - Check local firewall or network restrictions

4. **Import Errors**
   - Make sure all dependencies are installed
   - Check that you're running from the correct directory

### Performance Tips

- Use `gpt-4o-mini` for faster, cheaper runs
- Set `temperature=0.2` for more consistent outputs
- Add specific output length requirements in task descriptions
- Use virtual environments to avoid dependency conflicts

## 📚 Dependencies

### Core Dependencies
- `crewai`: Multi-agent orchestration framework
- `python-dotenv`: Environment variable management
- `nanda-adapter`: Wrapper that exposes Crew logic via an HTTP API
- `requests`: Utility HTTP client for integrations/tests

### Package Dependencies (pyproject.toml)
- `crewai>=0.30.0`: Multi-agent orchestration framework
- `mcp>=1.0.0`: Model Context Protocol server framework
- `requests`: HTTP client library
- `nanda-adapter`: NANDA integration adapter

## 🎓 How It Works

### NANDA HTTP API Flow
1. **Research Agent**: Acts as a Harvard Data Science student, researching and summarizing technical topics
2. **Mentor Agent**: Takes the research and rewrites it in beginner-friendly language
3. **Sequential Process**: Agents work one after another, with the mentor building on the research
4. **HTTP Response**: The final explanation is returned as text via the NANDA server API

### MCP Server Flow
1. **Same Agent Logic**: Uses identical CrewAI agents and workflow
2. **MCP Protocol**: Exposes the functionality via Model Context Protocol
3. **Tool Interface**: Provides `explain_topic` tool for MCP clients
4. **Stdio Transport**: Communicates via standard input/output for MCP integration

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## 📄 License

This project is part of the MIT AI Studio - CrewAI Tech Track.

## 🆘 Support

If you encounter issues:
1. Check the troubleshooting section above
2. Verify your API keys and dependencies
3. Ensure you're running from the correct directory
4. Check the CrewAI documentation for advanced configuration

## 📝 Example Output

When you send a topic like "SimCLR" to either server, the response contains a clear explanation with:
- **Definition**: What the concept is
- **Key Concepts**: Core ideas explained simply  
- **How It Works**: Step-by-step breakdown
- **Example Applications**: Real-world use cases
- **Why It Matters**: Importance and relevance

## 🧪 Testing

### Local Testing
Use the included `test_local.py` script to test the CrewAI logic directly:

```bash
python test_local.py
```

### NANDA Adapter Testing
Use `run_adapter.py` for testing the NANDA integration:

```bash
python run_adapter.py
```

## 🚀 Deployment Options

1. **NANDA HTTP API**: Perfect for web applications and external integrations
2. **MCP Server**: Ideal for AI tool integrations and MCP-compatible clients
3. **Direct Import**: Use `crew_agent_logic` function in your own Python applications

---

**Happy Learning with Luc's AI Agents! 🚀✨**
